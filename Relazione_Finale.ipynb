{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relazione finale\n",
    "\n",
    "**Gruppo:** Bug Data\n",
    "\n",
    "**Componenti del gruppo:** Jerin George Mathew, Luca Pasquini\n",
    "\n",
    "## 1. Indice\n",
    "La relazione è articolata nella seguente maniera:\n",
    "\n",
    "- #### Analisi del dataset\n",
    "- #### Specifiche hardware e software\n",
    "- #### Primo job\n",
    "    - *Map reduce*\n",
    "    - *Hive*\n",
    "    - *Spark*\n",
    "    - *Risultati*\n",
    "    - *Grafici*\n",
    "- #### Secondo job\n",
    "    - *Map reduce*\n",
    "    - *Hive*\n",
    "    - *Spark*\n",
    "    - *Risultati*\n",
    "    - *Grafici*\n",
    "- #### Terzo job\n",
    "    - *Map reduce*\n",
    "    - *Hive*\n",
    "    - *Spark*\n",
    "    - *Risultati*\n",
    "    - *Grafici*\n",
    "- #### Conclusioni\n",
    "\n",
    "Verrà dunque dapprima analizzato e descritto il dataset a disposizione per poi discutere l'implementazione dei job richiesti dal progetto nelle varie tecnologie richieste dalle specifiche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analisi del dataset\n",
    "Verranno analizzati in questa sezione i due dataset a disposizione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Importing libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "HISTORICAL_STOCK_PRICES_FILEPATH = 'dataset/historical_stock_prices.csv'\n",
    "HISTORICAL_STOCKS_FILEPATH = 'dataset/historical_stocks.csv'\n",
    "\n",
    "hsp = pd.read_csv(HISTORICAL_STOCK_PRICES_FILEPATH)\n",
    "hs = pd.read_csv(HISTORICAL_STOCKS_FILEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 `historical_stock_prices.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows and columns\n",
      "-----------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20973889, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"No. of rows and columns\")\n",
    "print(\"-----------------------\")\n",
    "hsp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dunque il file `historical_stock_prices.csv` è composto da 209738889 righe e 8 colonne. Stampiamo ora un sottoinsieme delle righe del file `historical_stock_prices.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AHH</td>\n",
       "      <td>11.50</td>\n",
       "      <td>11.58</td>\n",
       "      <td>8.493155</td>\n",
       "      <td>11.25</td>\n",
       "      <td>11.68</td>\n",
       "      <td>4633900</td>\n",
       "      <td>2013-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AHH</td>\n",
       "      <td>11.66</td>\n",
       "      <td>11.55</td>\n",
       "      <td>8.471151</td>\n",
       "      <td>11.50</td>\n",
       "      <td>11.66</td>\n",
       "      <td>275800</td>\n",
       "      <td>2013-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AHH</td>\n",
       "      <td>11.55</td>\n",
       "      <td>11.60</td>\n",
       "      <td>8.507822</td>\n",
       "      <td>11.50</td>\n",
       "      <td>11.60</td>\n",
       "      <td>277100</td>\n",
       "      <td>2013-05-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AHH</td>\n",
       "      <td>11.63</td>\n",
       "      <td>11.65</td>\n",
       "      <td>8.544494</td>\n",
       "      <td>11.55</td>\n",
       "      <td>11.65</td>\n",
       "      <td>147400</td>\n",
       "      <td>2013-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHH</td>\n",
       "      <td>11.60</td>\n",
       "      <td>11.53</td>\n",
       "      <td>8.456484</td>\n",
       "      <td>11.50</td>\n",
       "      <td>11.60</td>\n",
       "      <td>184100</td>\n",
       "      <td>2013-05-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker   open  close  adj_close    low   high   volume        date\n",
       "0    AHH  11.50  11.58   8.493155  11.25  11.68  4633900  2013-05-08\n",
       "1    AHH  11.66  11.55   8.471151  11.50  11.66   275800  2013-05-09\n",
       "2    AHH  11.55  11.60   8.507822  11.50  11.60   277100  2013-05-10\n",
       "3    AHH  11.63  11.65   8.544494  11.55  11.65   147400  2013-05-13\n",
       "4    AHH  11.60  11.53   8.456484  11.50  11.60   184100  2013-05-14"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come già detto nelle specifiche, il file `historical_stock_prices.csv` è composto dai seguenti campi:\n",
    "- ticker: simbolo dell’azione\n",
    "- open: prezzo di apertura\n",
    "- close: prezzo di chiusura\n",
    "- adj_close: prezzo di chiusura “modificato”\n",
    "- lowThe: prezzo minimo\n",
    "- highThe: prezzo massimo\n",
    "- volume: numero di transazioni\n",
    "- date: data nel formato aaaa-mm-gg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una attività preliminare all'implementazione vera e propria dei job è quella di data cleaning in cui si va a verificare la presenza di eventuali record non corretti (ad esempio contenenti valori nulli) che potrebbero essere presenti nel dataset. Verifichiamo in particolare che non siano presenti valori nulli nel file `historical_stock_prices.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check null values\n",
      "-----------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Check null values\")\n",
    "print(\"-----------------\")\n",
    "hsp.isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dunque non sono presenti valori nulli. Una altra attività che possiamo effettuare è andare a verificare che vi sia un record per ogni coppia `(ticker, data)`, ovvero che non siano presenti record duplicati per un certo `ticker` in una certa data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check duplicate values\n",
      "----------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Check duplicate values\")\n",
    "print(\"----------------------\")\n",
    "len(hsp.groupby(['ticker', 'date'])) != hsp.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passiamo ora ad analizzare il secondo dataset, `historical_stocks.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 `historical_stocks.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows and columns\n",
      "-----------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6460, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"No. of rows and columns\")\n",
    "print(\"-----------------------\")\n",
    "hs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>exchange</th>\n",
       "      <th>name</th>\n",
       "      <th>sector</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIH</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>1347 PROPERTY INSURANCE HOLDINGS, INC.</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>PROPERTY-CASUALTY INSURERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIHPP</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>1347 PROPERTY INSURANCE HOLDINGS, INC.</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>PROPERTY-CASUALTY INSURERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TURN</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>180 DEGREE CAPITAL CORP.</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>FINANCE/INVESTORS SERVICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FLWS</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>1-800 FLOWERS.COM, INC.</td>\n",
       "      <td>CONSUMER SERVICES</td>\n",
       "      <td>OTHER SPECIALTY STORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FCCY</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>1ST CONSTITUTION BANCORP (NJ)</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>SAVINGS INSTITUTIONS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker exchange                                    name             sector  \\\n",
       "0    PIH   NASDAQ  1347 PROPERTY INSURANCE HOLDINGS, INC.            FINANCE   \n",
       "1  PIHPP   NASDAQ  1347 PROPERTY INSURANCE HOLDINGS, INC.            FINANCE   \n",
       "2   TURN   NASDAQ                180 DEGREE CAPITAL CORP.            FINANCE   \n",
       "3   FLWS   NASDAQ                 1-800 FLOWERS.COM, INC.  CONSUMER SERVICES   \n",
       "4   FCCY   NASDAQ           1ST CONSTITUTION BANCORP (NJ)            FINANCE   \n",
       "\n",
       "                     industry  \n",
       "0  PROPERTY-CASUALTY INSURERS  \n",
       "1  PROPERTY-CASUALTY INSURERS  \n",
       "2  FINANCE/INVESTORS SERVICES  \n",
       "3      OTHER SPECIALTY STORES  \n",
       "4        SAVINGS INSTITUTIONS  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dunque il secondo dataset contiene 6460 righe e 5 campi:\n",
    "- ticker: simbolo dell’azione\n",
    "- exchange: NYSE o NASDAQ\n",
    "- name: nome dell’azienda\n",
    "- sector: settore dell’azienda\n",
    "- industry: industria di riferimento per l’azienda\n",
    "\n",
    "Vediamo anche per questo secondo dataset se sono presenti valori nulli e/o duplicati e stampiamo alcune statistiche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check null values\n",
      "-----------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Check null values\")\n",
    "print(\"-----------------\")\n",
    "hs.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker      False\n",
       "exchange    False\n",
       "name        False\n",
       "sector       True\n",
       "industry     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notiamo dunque come siano presenti dei campi, in particolare `sector` e `industry`  nel secondo dataset che presentano valori nulli. Stampiamo ora qualche record contenente valori nulli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>exchange</th>\n",
       "      <th>name</th>\n",
       "      <th>sector</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ABP</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>ABPRO CORPORATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SQZZ</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>ACTIVE ALTS CONTRARIAN ETF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ACT</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>ADVISORSHARES VICE ETF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>ABDC</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>ALCENTRA CAPITAL CORP.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>SMCP</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>ALPHAMARK ACTIVELY MANAGED SMALL CAP ETF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker exchange                                      name sector industry\n",
       "19     ABP   NASDAQ                         ABPRO CORPORATION    NaN      NaN\n",
       "42    SQZZ   NASDAQ                ACTIVE ALTS CONTRARIAN ETF    NaN      NaN\n",
       "62     ACT   NASDAQ                    ADVISORSHARES VICE ETF    NaN      NaN\n",
       "100   ABDC   NASDAQ                    ALCENTRA CAPITAL CORP.    NaN      NaN\n",
       "124   SMCP   NASDAQ  ALPHAMARK ACTIVELY MANAGED SMALL CAP ETF    NaN      NaN"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs[hs['sector'].isnull() | hs['industry'].isnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fase di implementazione dei job occorrerà dunque tenere a mente di ignorare i record contenenti valori nulli di `sector` e `industry`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check duplicate values\n",
      "----------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Check duplicate values\")\n",
    "print(\"----------------------\")\n",
    "len(hs['ticker']) != hs.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dunque non sono presenti valori duplicati per il file `historical_stocks.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 `historical_stocks.csv` + `historical_stock_prices.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facciamo ora il join tra i due dataset per effettuare poi ulteriori attività di analisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(hs, hsp, on = 'ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20973889, 12)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>exchange</th>\n",
       "      <th>name</th>\n",
       "      <th>sector</th>\n",
       "      <th>industry</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIH</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>1347 PROPERTY INSURANCE HOLDINGS, INC.</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>PROPERTY-CASUALTY INSURERS</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.95</td>\n",
       "      <td>7.95</td>\n",
       "      <td>7.90</td>\n",
       "      <td>8.50</td>\n",
       "      <td>642900</td>\n",
       "      <td>2014-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIH</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>1347 PROPERTY INSURANCE HOLDINGS, INC.</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>PROPERTY-CASUALTY INSURERS</td>\n",
       "      <td>7.94</td>\n",
       "      <td>8.16</td>\n",
       "      <td>8.16</td>\n",
       "      <td>7.90</td>\n",
       "      <td>8.29</td>\n",
       "      <td>228400</td>\n",
       "      <td>2014-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIH</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>1347 PROPERTY INSURANCE HOLDINGS, INC.</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>PROPERTY-CASUALTY INSURERS</td>\n",
       "      <td>8.29</td>\n",
       "      <td>8.39</td>\n",
       "      <td>8.39</td>\n",
       "      <td>8.05</td>\n",
       "      <td>8.40</td>\n",
       "      <td>105000</td>\n",
       "      <td>2014-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIH</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>1347 PROPERTY INSURANCE HOLDINGS, INC.</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>PROPERTY-CASUALTY INSURERS</td>\n",
       "      <td>8.50</td>\n",
       "      <td>8.69</td>\n",
       "      <td>8.69</td>\n",
       "      <td>8.32</td>\n",
       "      <td>8.70</td>\n",
       "      <td>113600</td>\n",
       "      <td>2014-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIH</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>1347 PROPERTY INSURANCE HOLDINGS, INC.</td>\n",
       "      <td>FINANCE</td>\n",
       "      <td>PROPERTY-CASUALTY INSURERS</td>\n",
       "      <td>9.00</td>\n",
       "      <td>8.94</td>\n",
       "      <td>8.94</td>\n",
       "      <td>8.55</td>\n",
       "      <td>9.00</td>\n",
       "      <td>60500</td>\n",
       "      <td>2014-04-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker exchange                                    name   sector  \\\n",
       "0    PIH   NASDAQ  1347 PROPERTY INSURANCE HOLDINGS, INC.  FINANCE   \n",
       "1    PIH   NASDAQ  1347 PROPERTY INSURANCE HOLDINGS, INC.  FINANCE   \n",
       "2    PIH   NASDAQ  1347 PROPERTY INSURANCE HOLDINGS, INC.  FINANCE   \n",
       "3    PIH   NASDAQ  1347 PROPERTY INSURANCE HOLDINGS, INC.  FINANCE   \n",
       "4    PIH   NASDAQ  1347 PROPERTY INSURANCE HOLDINGS, INC.  FINANCE   \n",
       "\n",
       "                     industry  open  close  adj_close   low  high  volume  \\\n",
       "0  PROPERTY-CASUALTY INSURERS  8.00   7.95       7.95  7.90  8.50  642900   \n",
       "1  PROPERTY-CASUALTY INSURERS  7.94   8.16       8.16  7.90  8.29  228400   \n",
       "2  PROPERTY-CASUALTY INSURERS  8.29   8.39       8.39  8.05  8.40  105000   \n",
       "3  PROPERTY-CASUALTY INSURERS  8.50   8.69       8.69  8.32  8.70  113600   \n",
       "4  PROPERTY-CASUALTY INSURERS  9.00   8.94       8.94  8.55  9.00   60500   \n",
       "\n",
       "         date  \n",
       "0  2014-04-01  \n",
       "1  2014-04-02  \n",
       "2  2014-04-03  \n",
       "3  2014-04-04  \n",
       "4  2014-04-07  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ad esempio possiamo verificare se una certa compagnia dispone di più di una azione (ovvero la presenza di un un nome (`name`) di compagnia associato a più di un `ticker`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('name')['ticker'].nunique().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BARCLAYS PLC'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('name')['ticker'].nunique().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BARCLAYS PLC', 'BCS'),\n",
       " ('BARCLAYS PLC', 'DFVL'),\n",
       " ('BARCLAYS PLC', 'DFVS'),\n",
       " ('BARCLAYS PLC', 'DLBL'),\n",
       " ('BARCLAYS PLC', 'DLBS'),\n",
       " ('BARCLAYS PLC', 'DTUL'),\n",
       " ('BARCLAYS PLC', 'DTUS'),\n",
       " ('BARCLAYS PLC', 'DTYL'),\n",
       " ('BARCLAYS PLC', 'DTYS'),\n",
       " ('BARCLAYS PLC', 'FLAT'),\n",
       " ('BARCLAYS PLC', 'STPP'),\n",
       " ('BARCLAYS PLC', 'TAPR')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[df['name'] == 'BARCLAYS PLC'].groupby(['name', 'ticker']).groups.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo notare ad esempio come **_BARCLAYS PLC_** abbia ben 12 `ticker`.\n",
    "\n",
    "Verifichiamo ora se vi sono aziende (nomi di aziende) associate a più di un settore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('name')['sector'].nunique().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ENERGIZER HOLDINGS, INC.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('name')['sector'].nunique().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ENERGIZER HOLDINGS, INC.', 'CONSUMER NON-DURABLES'),\n",
       " ('ENERGIZER HOLDINGS, INC.', 'MISCELLANEOUS')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[df['name'] == 'ENERGIZER HOLDINGS, INC.'].groupby(['name', 'sector']).groups.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo notare ad esempio come **_ENERGIZER HOLDINGS, INC._** sia associato a due settori.\n",
    "\n",
    "Un'ulteriore controllo che possiamo effettuare sta nel verificare se sono presenti compagnie che sono quotate sia nel NYSE che nel NASDAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('name')['exchange'].nunique().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AMTRUST FINANCIAL SERVICES, INC.'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('name')['exchange'].nunique().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AMTRUST FINANCIAL SERVICES, INC.', 'NASDAQ'),\n",
       " ('AMTRUST FINANCIAL SERVICES, INC.', 'NYSE')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df[df['name'] == 'AMTRUST FINANCIAL SERVICES, INC.'].groupby(['name', 'exchange']).groups.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notiamo come ad esempio **_AMTRUST FINANCIAL SERVICES, INC._** sia quotata in entrambe le borse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Primo Job\n",
    "\n",
    "### 3.1 Specifiche\n",
    "Implementare un job che sia in grado di generare, in ordine, le dieci azioni la cui quotazione (prezzo di chiusura) è cresciuta maggiormente dal 1998 al 2018, indicando, per ogni azione: (a) il simbolo, (b) l’incremento percentuale, (c) il prezzo minimo raggiunto, (e) quello massimo e (f) il volume medio giornaliero in quell’intervallo temporale.\n",
    "\n",
    "### 3.2 Implementazione in MapReduce\n",
    "\n",
    "**Mapper**\n",
    "\n",
    "In fase di mapping estrapoliamo innanzitutto da ciascun record i campi `ticker`, `close`, `low`, `high`, `volume` e `date`.\n",
    "\n",
    "Successivamente verifichiamo che il record sia relativo ad un anno che ricada nell'intervallo 1998-2018, per poi stampare la chiave i valori associati alla chiave. \n",
    "In particolare la chiave è composta da due campi: `ticker`, usata come chiave \"primaria\", e `date` usata come chiave \"secondaria\".\n",
    "\n",
    "In questo modo valori che verranno ricevuti dal reducer saranno aggregati per il solo campo `ticker` e ordinati in base al campo `date` (si parla in questo caso di _secondary sort_). Questo consentirà nella fase di reduce di evitare comparazioni tra date ai fini del calcolo della differenza percentuale.\n",
    "\n",
    "\n",
    "I valori sono nello specifico i campi `close`, `low`, `high` e `volume`.\n",
    "\n",
    "```python\n",
    "class mapper:\n",
    "    \n",
    "    map(key, record):\n",
    "        ticker, _, close, _, low, high, volume, date = data\n",
    "        year = getYear(date)\n",
    "        if 1998 <= year <= 2018:\n",
    "            key = ticker, date\n",
    "            value = close, low, high, volume\n",
    "            Emit(key, value)\n",
    "```\n",
    "\n",
    "**Reducer**\n",
    "\n",
    "Durante la fase di reduce definiamo una variabile globale `result` contenente una lista di strutture dati che chiameremo di seguito `item`, ciascuno dei quali contiene i seguenti campi:\n",
    "\n",
    "- ticker\n",
    "- differenza percentuale\n",
    "- volume medio\n",
    "- prezzo minimo\n",
    "- prezzo massimo\n",
    "\n",
    "In particolare ciascun `item` viene calcolato a partire da un data coppia chiave-valore in fase di reduce.\n",
    "\n",
    "Si descrive ora come vengono calcolati gli ultimi 4 campi di questa struttura dati.\n",
    "\n",
    "In particolare, per calcolare la differenza percentuale estraiamo dalla lista `values` (si veda lo pseudocodice) il campo `close` del primo e dell'ultimo elemento della lista, essendo i valori associati ai ticker ordinati per data. Si procede poi al calcolo della differenza percentuale. \n",
    "\n",
    "Per quanto riguarda il volume medio, si estraggono i valori di `volume` associati al `ticker` corrente, si sommano tali valori e si divide il risultato per il numero di `volume`. \n",
    "\n",
    "Infine per poter calcolare il prezzo massimo e minimo, si estraggono i campi `low` e `high` da ciascun elemento della lista per individuare poi il prezzo minimo e massimo. \n",
    "\n",
    "I valori così calcolati vengono poi salvati nella struttura dati `item`. A questo punto si verifica che la data meno recente del ticker corrente sia il 1998 come pure che la data più recente associata al `ticker` processato sia nell'anno 2018 (ai fini di filtrare le aziende che esistono tutt'ora oggi) e, in caso di esito positivo, la struttura dati `item` così computata viene aggiunta alla lista `result`. \n",
    "\n",
    "Infine, una volta computati tutti i ticker, la lista `result` viene ordinata in base al campo `percentChange` dei suoi elementi (in ordine decrescente) e vengono stampati i primi 10 di tale lista ordinata.\n",
    "\n",
    "```python\n",
    "class reducer:\n",
    "    \n",
    "    setup():\n",
    "        result = empty list\n",
    "\n",
    "    reduce(key, records):\n",
    "\n",
    "        # get percent change\n",
    "        startingClosePrice = values.getFirstElement().getClose()\n",
    "        endingClosePrice = values.getLastElement.getClose()\n",
    "        percentChange = (endingClosePrice - startingClosePrice)/startingClosePrice\n",
    "\n",
    "        # get volume\n",
    "        volumeValues = values.getVolumes()\n",
    "        totalVolume = 0\n",
    "        count = 0\n",
    "        for each volume in volumeValues:\n",
    "            totalVolume += volume\n",
    "            count += 1\n",
    "        averageVolume = totalVolume/count\n",
    "\n",
    "        # get minimum low price\n",
    "        lowValues = values.getLowValues()\n",
    "        minLow = infinity\n",
    "        for low in lowValues:\n",
    "            minLow = min(minLow, low)\n",
    "\n",
    "        # get maximum high price\n",
    "        highValues = values.getHighValues()\n",
    "        maxHigh = - infinity\n",
    "        for high in highValues:\n",
    "            maxHigh = max(maxHigh, high)\n",
    "\n",
    "        # add this item to result list\n",
    "        startingDate = values.getFirstElement().getYear()\n",
    "        endingDate = values.getLastElement().getYear()\n",
    "        if startingDate == 1998 and endingDate == 2018:\n",
    "            obj = {ticker, percentChange, minLow, maxHigh, averageVolume}\n",
    "            result.append(obj)\n",
    "    \n",
    "    cleanup()\n",
    "        sortedResult = sortByPercentChange(results, reverse=True)\n",
    "        for i in range(10):\n",
    "            Emit(sortedResult.getItem(i))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Implementazione in Hive\n",
    "\n",
    "Vengono definite complessivamente 6 viste:\n",
    "\n",
    "- `ticker_min_max_avg`, contenente il minimo valore di `low` e il massimo valore di `high` per ogni `ticker`\n",
    "- `ticker_min_data` e `ticker_close_min_data`, contenenti la data meno recente e il corrispondente valore di `close` per ciascun `ticker` rispettivamente\n",
    "- `ticker_max_data` e `ticker_close_max_data`, contenenti la data più recente e il corrispondente valore di `close` per ciascun `ticker` rispettivamente\n",
    "- `ticker_percentuale`, che calcola l'incremento percentuale per ciascun `ticker` a partire dalle viste precedenti\n",
    "\n",
    "Infine viene effettuato un join tra le viste `ticker_min_max_avg` e `ticker_percentuale` per ottenere il risultato richiesto.\n",
    "\n",
    "```SQL\n",
    "\n",
    "CREATE VIEW IF NOT EXISTS ticker_min_max_avg AS \n",
    "SELECT ticker, min(low) AS min_price, max(high) AS max_price, avg(volume) AS avg_volume \n",
    "FROM historical_stock_prices \n",
    "WHERE YEAR(data)>=1998 AND YEAR(data)<=2018 GROUP BY ticker;\n",
    "\n",
    "CREATE VIEW IF NOT EXISTS ticker_min_data AS \n",
    "SELECT ticker, min(TO_DATE(data)) AS min_data \n",
    "FROM historical_stock_prices \n",
    "WHERE YEAR(data)==1998 \n",
    "GROUP BY ticker;\n",
    "\n",
    "CREATE VIEW IF NOT EXISTS ticker_max_data AS \n",
    "SELECT ticker, max(TO_DATE(data)) AS max_data \n",
    "FROM historical_stock_prices \n",
    "WHERE YEAR(data)==2018 \n",
    "GROUP BY ticker;\n",
    "\n",
    "CREATE VIEW IF NOT EXISTS ticker_close_min_data AS \n",
    "SELECT h.ticker, h.data, h.close \n",
    "FROM ticker_min_data AS t, historical_stock_prices AS h \n",
    "WHERE h.ticker=t.ticker AND h.data=t.min_data;\n",
    "\n",
    "CREATE VIEW IF NOT EXISTS ticker_close_max_data AS \n",
    "SELECT h.ticker, h.data, h.close \n",
    "FROM ticker_max_data AS t, historical_stock_prices AS h \n",
    "WHERE h.ticker=t.ticker AND h.data=t.max_data;\n",
    "\n",
    "CREATE VIEW IF NOT EXISTS ticker_percentuale AS \n",
    "SELECT mi.ticker, ((ma.close-mi.close)/mi.close) AS inc_perc \n",
    "FROM ticker_close_max_data AS ma join ticker_close_min_data AS mi on ma.ticker=mi.ticker;\n",
    "\n",
    "INSERT OVERWRITE LOCAL DIRECTORY 'output/'\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY '\\t' \n",
    "SELECT a.ticker, b.inc_perc, a.min_price, a.max_price, a.avg_volume \n",
    "FROM ticker_min_max_avg AS a join ticker_percentuale AS b on a.ticker=b.ticker \n",
    "ORDER BY b.inc_perc DESC limit 10;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Implementazione in Spark\n",
    "\n",
    "Si descrive ora l'implementazione del job in Spark. Vengono principalmente definiti i seguenti `RDD`:\n",
    "\n",
    "- `min_ticker_low`, contenente per ciasun ticker il prezzo di chiusura minimo\n",
    "- `max_ticker_high`, contenente per ciasun ticker il prezzo di chiusura massimo\n",
    "- `avg_ticker_volume`, contenente per ciascun ticker il volume medio giornaliero\n",
    "- `min_data_close`, che associa ad un dato ticker il prezzo di chiusura relativo alla data meno recente\n",
    "- `max_data_close`, che associa ad un dato ticker il prezzo di chiusura relativo alla data più recente\n",
    "\n",
    "Si effettua poi il join tra `min_data_close` e `max_data_close` per ottenere `join_inc_perc`. \n",
    "\n",
    "A partire da `join_inc_perc` viene calcolato l'incremento percentuale per ciascun ticker (`inc_perc`). \n",
    "\n",
    "Infine viene fatto il join tra `inc_perc`,`avg_ticker_volume`, `min_ticker_low` e `max_ticker_high`, per poi ordinare il risultato in base all'incremento percentuale (in ordine decrescente) estraendo infine i primi 10 elementi di tale `RDD` ordinato.\n",
    "\n",
    "```python\n",
    "input = leggi tutte le righe del file historical_stock_prices.csv\n",
    "        con data compresa tra il 1998 e il 2018\n",
    "\n",
    "min_ticker_low = input.map(riga → (ticker, low))\n",
    "\t\t              .reduceByKey(min(low1, low2))\n",
    "\n",
    "max_ticker_high = input.map(riga → (ticker, high))\n",
    "\t\t\t           .reduceByKey(max(high1, high2))\n",
    "\n",
    "avg_ticker_volume = input.map(riga → (ticker, (volume,1)))\n",
    "                         .reduceByKey((volume1+volume2, count+1))\n",
    "                         .map(riga→(ticker, TotVolume/count))\n",
    "\n",
    "min_data_close = input.map(riga → (ticker, (close, data)))\n",
    "                      .reduceByKey(minimo((data1,close1), (data2,close2)))\n",
    "                      .filter(data.year == \"1998\")\t\n",
    "\n",
    "max_data_close = input.map(riga → (ticker, (close, data)))\n",
    "                      .reduceByKey(massimo((data1,close1), (data2,close2)))\n",
    "                      .filter(data.year == \"2018\")\n",
    "\n",
    "join_inc_perc = min_data_close\n",
    "                    .join(max_data_close)\n",
    "    \n",
    "inc_perc = join_inc_perc\n",
    "                .map(riga → (ticker, (maxclose-minclose)/minclose))\n",
    "\n",
    "result = max_ticker_high\n",
    "            .join(min_ticker_low)\n",
    "            .join(inc_perc)\n",
    "            .join(avg_ticker_volume)\n",
    "            .sortBy(incremento percentuale decrescente)\n",
    "            .take(10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Risultati\n",
    "\n",
    "Si mostra ora l'output restituito per il primo job:\n",
    "\n",
    "```\n",
    "MNST  163340.387616%  0.0305979158729  70.2200012207  7347898.8208\n",
    "AMZN  38328.032677%   4.14583349228    1925.0         7868702.73287\n",
    "AAPL  37146.0319467%  0.482142865658   219.179992676  121398558.199\n",
    "CTSH  36312.8011611%  0.145833328366   85.0999984741  6272137.93307\n",
    "CELG  24924.0000849%  0.171875         147.169998169  8002695.57352\n",
    "WP    24012.4988778%  0.0500000007451  96.5100021362  1270066.16934\n",
    "MED   13733.2303561%  0.0936999991536  229.199996948  223768.309139\n",
    "NVR   11786.7001488%  21.625           3700.0         56463.7413395\n",
    "ANSS  10077.1432059%  1.375            184.949996948  482841.405197\n",
    "TSCO  9508.67816472%  0.40625          97.25          1592298.53705\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Grafici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Job 2\n",
    "\n",
    "### 4.1 Specifiche\n",
    "Realizzare job che sia in grado di generare, per ciascun settore, il relativo “trend” nel periodo 2004-2018 ovvero un elenco contenete, per ciascun anno nell’intervallo: (a) il volume complessivo del settore, (b) la percentuale di variazione annuale (differenza percentuale arrotondata tra la quotazione di fine anno e quella di inizio anno) e (c) la quotazione giornaliera media. N.B.: volume e quotazione di un settore si ottengono sommando i relativi valori di tutte le azioni del settore.\n",
    "\n",
    "### 4.2 Implementazione in MapReduce\n",
    "\n",
    "**Mapper**:\n",
    "\n",
    "Leggiamo dapprima, utilizzando la _Distributed Cache_ (https://hadoop.apache.org/docs/r3.0.0/api/org/apache/hadoop/filecache/DistributedCache.html) il file `historical_stocks.csv`, per poi definire, a partire dallo stesso file, una struttura dati (`tickerToSectorMap`) che associa a ciascun `ticker` il corrispondente settore (escludendo i `ticker` privi di un corrispondente settore).\n",
    "\n",
    "La struttura dati così creata verrà usata per poter poi effettuare in seguito il \"join\" con i record del file `historical_stock_prices.csv` associando a ciascun record il settore del `ticker` corrispondente.\n",
    "\n",
    "In fase di mapping estrapoliamo da ciascun record i campi `ticker`, `close`, `volume` e `date`, verifichiamo che il record sia relativo ad un anno che ricada nell'intervallo 2004-2018 per poi stampare i campi estratti da quest'ultimo. In particolare la chiave è composta da due campi: `ticker`, usata come chiave primaria, e `date` usata come chiave secondaria. I valori sono invece i campi `close`, `low`, `high` e `volume`. In questo modo, in fase di reduce, i valori associati a ciascun `ticker` saranno ordinati per data, in maniera tale da evitare comparazioni tra date ai fini del calcolo della differenza percentuale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
